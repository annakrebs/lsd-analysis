 # @author         Anna-Barbara Krebs
 # @name           sparql.R  
 # @date           xx.xx.xxxx     
 # @fileOverview   Contains SPARQL Query to retrieve the required data for   
 #                 the Grouped Bar Analysis from the SPARQL endpoints. 
 #                 Contains SPARQL Update to insert the results generated by the 
 #                 Grouped Bar Analysis into an RDF graph in the Graph Store.
 #                 
 #          Note:  Some of the code has been adopted from Sarven Capadisli, from
 #                 the files "sparql.R" which are used for the Regression and  
 #                 Time Series Analysis. 

prefixes <- paste0("PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX qb: <http://purl.org/linked-data/cube#>
PREFIX sdmx: <http://purl.org/linked-data/sdmx#>
PREFIX sdmx-dimension: <http://purl.org/linked-data/sdmx/2009/dimension#>
PREFIX sdmx-measure: <http://purl.org/linked-data/sdmx/2009/measure#>
PREFIX year: <http://reference.data.gov.uk/id/year/>
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX stats: <http://stats.270a.info/vocab#>
PREFIX provenance: <", siteURI, "provenance/>
")

# SPARQL Update
sparqlUpdateGroupedBarPlot <- function(analysisURI, dataset, refArea, refPeriod, data, analysis) { 

    sparqlQueryStringEncoded <- URLencode(sparqlQueryStringGroupedBarPlot(dataset, refArea, refPeriod), reserved=TRUE) 

    # Genereates vector of Datasets -> [2]http://worldbank.../../SE.XPD.PRIM.PC.ZS [3]http://worldbank.../../SE.XPD.SECO.PC.ZS 
    d <- strsplit(c(d = dataset), ",") # splits different datasets in URI at ","
    ds = ''    
    # Loop over datasets
    for (i in 1:length(d$d)) { # length(d$d) = amount of datasets
         t <- strsplit(c(t=d$d[i]), ":") # splits dataset at ":" to  retrieve prefix and dataset
         dataset <- paste0(namespaces[t$t[1]], t$t[2]) # puts namespace in front of dataset -> http://worldbank.270a.info/dataset/SE.XPD.PRIM.PC.ZS
         ds <- append(ds, dataset) # appends all dataset names in one vector
    }
    dataset <- ds # "dataset" -> vector which consists of all datasets in URI [2]http://worldbank.../../SE.XPD.PRIM.PC.ZS [3]http://worldbank.../../SE.XPD.SECO.PC.ZS 

    s <- strsplit(c(s = refArea), ",") # splits different refAreas in URI at "," -> "CH,FR,US"


#FIXME: xsd:decimal assignment is problematic because not all values are xsd:decimal!


    # Generates RDF representation of the Grouped Bar Analysis results
    # Generates RDF triples of the data retrieved from the Grouped Bar Analysis results
    statsData <- paste0("<", analysisURI, ">")
    for (i in 1:length(data[, 1])) { 
        statsData <- paste0(statsData, "
            stats:data [
                a stats:DataRow ;
                stats:refArea <", paste0(namespaces$wbcountry, data[i, 'refArea']), "> ;
 
        ")

        # Loop through measureVariables to retrieve observation values -> stats:measure "23.20144"^^xsd:decimal ;
        for (j in 2:length(data[1, ])) { # 2:length(data[1, ]) = amount of measureVariables 
            statsData <- paste0(statsData, "
                stats:measure \"", data[i, j], "\"^^xsd:decimal ;
            ")
        } # "data[i, 2]" -> is observation value (e.g. "23.20144") in first column of measureVariable (e.g. "abcdef")
        statsData <- paste0(statsData, "
            ] ;"
        )
    }

    # Generates RDF triples of the data of the summary retrieved from the Grouped Bar Analysis results (e.g. min, q1, mean)
    statsSummary <- paste0("<", analysisURI, ">") # Abschnitt hinzugef√ºgt
    for (i in 2:length(analysis$meta[, 1])) { # gets data from "meta" in "getAnalysisGroupedBarPlot" in analysis.R
        statsSummary <- paste0(statsSummary, "
            stats:summary [
                a stats:Summary ;
                stats:dataset <", dataset[i], "> ;
                stats:min \"", analysis$meta$minValues[i], "\"^^xsd:decimal ; 
                stats:q1 \"", analysis$meta$q1Values[i], "\"^^xsd:decimal ;
                stats:mean \"", analysis$meta$meanValues[i], "\"^^xsd:decimal ;
                stats:q3 \"", analysis$meta$q3Values[i], "\"^^xsd:decimal ;
                stats:max \"", analysis$meta$maxValues[i], "\"^^xsd:decimal ;
                stats:median \"", analysis$meta$medianValues[i], "\"^^xsd:decimal ;
            ")       

        statsSummary <- paste0(statsSummary, "            
                stats:n \"", analysis$meta[i, 'n'], "\"^^xsd:double
            ] ;"
        )
    }


    now <- strftime(Sys.time(), "%Y-%m-%dT%H:%M:%SZ")

    plotURI <- paste0(siteURI, "plots/", digest(paste0(dataset, refArea, refPeriod), algo="sha1", serialize=FALSE), ".svg") 

    sparqlQueryURI <- paste0("<", sparqlEndpoints$stats, "?query=", sparqlQueryStringEncoded, ">")
 

    # Generates resourceLabels of the datasets and pastes dataset names togehter, seperating them with "and" 
    for (i in 2:length(data[1, ])) { # 2:length(data[1, ]) = amount of measureVariable
        if (i == 2) { # [2] is first dataset with vaule -> [1] = ""
            rL <- paste(resourceLabels[dataset[i]], sep="") # first dataset is not preceded by "and"
        }
        else {
            rL <- paste(rL, resourceLabels[dataset[i]], sep=" and ") # separates different datasets with "and"
        }
    } 


    # Inserts RDF triples in Graph Store
    query <- paste0("
INSERT DATA {
    GRAPH <http://stats.270a.info/graph/analysis> {
        ", sparqlQueryURI, "
            rdfs:label \"SPARQL Query URI to retrieve the data for '", rL, "'\"@en .

        provenance:", analysis$id, "
            a prov:Activity ;
            rdfs:label \"Generated Analysis '", rL, "'\"@en ;

            prov:startedAtTime \"", now, "\"^^xsd:dateTime ;
            prov:wasAssociatedWith <http://csarven.ca/#i> ;
            prov:used ", sparqlQueryURI, " ;
            prov:used <https://github.com/csarven/lsd-analysis> ;
        ")

        # Loop through measureVariables to retrieve all dataset URIs -> prov:used <http://worldbank.270a.info/dataset/SE.XPD.PRIM.PC.ZS> ;
        for (i in 2:length(data[1, ])) { # 2:length(data[1, ]) = amount of measureVariables
            query <- paste0(query, "
                prov:used <", dataset[i], "> ;
            ")
        }
        # Loop through obsValues to retrieve all refAreas names and adds namespace from World Bank in order to get URI of refArea
        for(i in 1:length(data[, 1])) { # 1:length(data[, 1]) = amount of obsValues
            if (i == 1) { #  URI of first refArea
                query <- paste0(query, "
                    prov:used <", paste0(namespaces$wbcountry, data[i, 'refArea']), "> ;
                ") 
            }
            else { # URI of all the other refAreas
                if (data[i-1, 'refArea'] != data[i, 'refArea']) { # checks whether same refArea has already been outputed -> only displays the same refArea once
                    query <- paste0(query, "
                        prov:used <", paste0(namespaces$wbcountry, data[i, 'refArea']), "> ;
                    ") 
                }
            } 
        }

        query <- paste0(query, "  
            prov:generated <", analysisURI, "> ;
            dcterms:license <", licenseURI, ">
        .

        <", analysisURI, ">
            a stats:Analysis ;
            a prov:Entity ;        
            rdfs:label \"Analysis of '", rL, "'\"@en ;

            prov:wasGeneratedBy provenance:", analysis$id, " ;
            prov:generatedAtTime \"", now, "\"^^xsd:dateTime ;
            prov:wasDerivedFrom ", sparqlQueryURI, " ;
            prov:wasAttributedTo <", creatorURI, "> ;
            dcterms:creator <", creatorURI, "> ;
            dcterms:license <", licenseURI, "> ;

            stats:graph <", plotURI ,"> ;
        ")

        # Loop through measureVariables to retrieve dataset URIs -> stats:dataset <http://worldbank.270a.info/dataset/SE.XPD.PRIM.PC.ZS> ;
        for (i in 2:length(data[1, ])) { # 2:length(data[1, ]) = amount of measureVariables
            query <- paste0(query, "
                stats:dataset <", dataset[i], "> ;
            ")
        }
        # Loop through obsValues to retrieve all refAreas names and adds namespace from World Bank in order to get URI
        for(i in 1:length(data[, 1])) { # 1:length(data[, 1]) = amount of obsValues
            if (i == 1) { # URI of first refArea
                query <- paste0(query, "
                    stats:refArea <", paste0(namespaces$wbcountry, data[i, 'refArea']), "> ;
                ") 
            }
            else { # URI of all the other refAreas
                if (data[i-1, 'refArea'] != data[i, 'refArea']) { # checks whether same refArea has already been outputed -> only displays the same refArea once
                    query <- paste0(query, "
                        stats:refArea <", paste0(namespaces$wbcountry, data[i, 'refArea']), "> ;
                    ") 
                }
            } 
        }

        # TODO: shows values appropriately?
        for (i in 2:length(analysis$meta[, 1])) { # gets data from "meta" in "getAnalysisGroupedBarPlot" in analysis.R
            query <- paste0(query, "                         
                stats:min \"", analysis$meta$minValues[i], "\"^^xsd:decimal ; 
                stats:q1 \"", analysis$meta$q1Values[i], "\"^^xsd:decimal ;
                stats:mean \"", analysis$meta$meanValues[i], "\"^^xsd:decimal ;
                stats:q3 \"", analysis$meta$q3Values[i], "\"^^xsd:decimal ;
                stats:max \"", analysis$meta$maxValues[i], "\"^^xsd:decimal ;
                stats:median \"", analysis$meta$medianValues[i], "\"^^xsd:decimal ;
                ")
        }
        query <- paste0(query, "
        stats:n \"", nrow(data), "\"^^xsd:integer

        .

        ", statsData, "
        .

        ", statsSummary, "
        .
    }
}
")
    q <- paste0(prefixes, query)
    r <- SPARQL(sparqlServiceUpdateURI, update=q, curl_args=list(style="post"))

    return(r)
}



sparqlQueryGetAnalysisSummaryGroupedBarPlot <- function(analysisURI) {

    q <- paste0("
PREFIX stats: <http://stats.270a.info/vocab#>

SELECT *
WHERE {
    GRAPH <http://stats.270a.info/graph/analysis> {
        <", analysisURI, ">
            stats:dataset ?dataset ; 
            stats:refArea ?refArea ;
            stats:graph ?graph ;
            stats:n ?n ;
            stats:min ?min ;
            stats:q1 ?q1 ;
            stats:mean ?mean ;
            stats:q3 ?q3 ;
            stats:max ?max ;
            stats:median ?median  
 
    }
}
");

            #stats:dataset ?dataset ; 
            #stats:refArea ?refArea ; 
            #stats:refPeriod ?refPeriod ;
            #stats:graph ?graph ;
            #stats:n ?n ;
            #stats:minValues ?minValues ;
            #stats:q1Values ?q1Values ;
            #stats:meanValues ?meanValues ;
            #stats:q3Values ?q3Values ;
            #stats:maxValues ?maxValues ;
            #stats:medianValues ?medianValues 

    r <- SPARQL(sparqlServiceQueryURI, q)
    return(r$results)
}



sparqlQueryGroupedBarPlot <- function(dataset, refArea, refPeriod) { 
    q <- sparqlQueryStringGroupedBarPlot(dataset, refArea, refPeriod)
    r <- SPARQL(sparqlEndpoints$stats, q)
    return(r$results)
}

# SPARQL Query
sparqlQueryStringGroupedBarPlot <- function(dataset, refArea, refPeriod) { # gets data from sQGroupedBarPlot(....) in server.R

    d <- strsplit(c(d = dataset), ",") # splits different datasets in URI at ","

    endpoints = ''
    datasetNames = ''
    ds = ''
    
    # Looping over datasets
    for (i in 1:length(d$d)) { # length(d$d) = amount of datasets
         t <- strsplit(c(t=d$d[i]), ":") # splits dataset at ":" to retrieve prefix and dataset
         dataset <- paste0(namespaces[t$t[1]], t$t[2]) # puts namespace before dataset -> http://worldbank.270a.info/dataset/SE.XPD.PRIM.PC.ZS
         datasetName <- gsub("http://([^.]*).270a.info/dataset/.*", "\\1", dataset, perl=TRUE)
         datasetNames <- append(datasetNames, datasetName) # appends all prefixes in a vector -> "worldbank" "transparency" "worldbank" 
         endpoints <- append(endpoints, sparqlEndpoints[datasetName]) # appends all endpoint names -> "http://worldbank.270a.info/sparql"
         ds <- append(ds, dataset) # appends all dataset URIs -> http://worldbank.270a.info/dataset/SE.XPD.PRIM.PC.ZS
    }
    dataset <- ds # "dataset" contains all datasets of URI -> [2]http://worldbank.../../SE.XPD.PRIM.PC.ZS [3]http://worldbank.../../SE.XPD.SECO.PC.ZS 

        
    s <- strsplit(c(s = refArea), ",") # splits different refAreas in URI at "," -> "CH,FR,US"


    # Generates random measureVariables according to the amount of datasets that will be used in SELECT part of query -> ?abcdefghij
    measureVariables = ''
    # Loop endpoints
    for (i in 1:length(d$d)) { # length(d$d) = amount of datasets
        getRandString <- function(len=10) return(paste(sample(c(letters),len,replace=TRUE),collapse='')) # generates random string of length 10
        c = getRandString()

        # "?abcdef ?uvwxyz"
        measureVariables = paste(measureVariables, c, sep=" ?") # pastes strings together and puts "?" in front of string -> ?abcdef ?uvwxyz        
    } 
    mV <- strsplit(measureVariables, " ") # splits measureVariables at " ", so they can be used seperately in query
                                          # mV[[1]][2] = "?abcdef" # calls first relevant measureVariable 
                                          # mV[[1]][3] = "?uvwxyz" # calls second relevant measureVariable  


    # Generates FILTER according to the amount of refAreas that will be used in the query 
    refAreaFILTER = "FILTER (" # "refAreaFILTER" will be used in SPARQL query
    # Loop refAreas
    for (i in 1:length(s$s)) { # length(s$s) = amount of refAreas 
        rA = paste0("?refArea = '", s$s[i], "'")

        if (i == 1) { # first refArea is not preceded by "||"
            refAreaFILTER = paste(refAreaFILTER, rA, sep="") # "FILTER (?refArea  = 'FR')"
        }
        else {  # puts together "refArea = 'XX'" FILTER-parts and seperates them with "||"
            refAreaFILTER = paste(refAreaFILTER, rA, sep=" || ")  # "FILTER (?refArea  = 'FR' || ?refArea  = 'US')"
        }                    
    }
    refAreaFILTER = paste(refAreaFILTER, ")", sep="") # closes FILTER bracket at the end of the FILTER
    # refAreaFILTER = FILTER (?refArea = 'FR' || ?refArea = 'US')    


    # Generates SPARQL Query
    # lists all the measureVariables -> "SELECT DISTINCT ?refArea ?abcdef ?uvwxyz"
    query <- paste0("
        SELECT DISTINCT ?refArea ", measureVariables, " 
        WHERE {
    ")
    # Loop endpoints
    # SERVICE call is made for each dataset in URI
    for(i in 2:length(endpoints)) {  # begins at [2] because [1] = ""
     
        # mV[[1]][2] -> "?abcdef"
        query <- paste0(query, "
            SERVICE <",endpoints[i],"> {                
                SELECT DISTINCT ?refArea ", mV[[1]][i], "  
                WHERE {
                    ?observation qb:dataSet <", dataset[i], "> .

                    ?propertyRefArea rdfs:subPropertyOf* sdmx-dimension:refArea .
                    ?observation ?propertyRefArea ?refAreaEndpoint . 

                    ?observation ?propertyRefPeriod year:", refPeriod, " . 

                    ?propertyMeasure rdfs:subPropertyOf* sdmx-measure:obsValue .
                    ?observation ?propertyMeasure ", mV[[1]][i], " .

                    ?refAreaEndpoint skos:notation* ?refArea . 
 
                    ", refAreaFILTER, " 
                }
            }
        ")

    }

    query <- paste0(query, "
        }
    #ORDER BY ?refArea 
    ")
        


        q <- paste(prefixes, query)
#        print(q)

        return(q)


#    }
#    else {
#        #TODO: Error: Unrecognized dataset
#    }
}
